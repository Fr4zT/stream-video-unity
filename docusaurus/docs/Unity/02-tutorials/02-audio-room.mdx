---
title: How to Build an Android Audio Room with Kotlin
description: How to build an audio room using Stream's video SDKs
---

import { TokenSnippet } from '../../../shared/_tokenSnippet.jsx';

# Introduction


Although we called our product "Video SDK" please note that you can use audio only if you wish so.

This is exactly what we'll be doing in this tutorial - we'll setup Audio Rooms to which users can join and talk to each other. This is a very similar use case to when you'd want to implement a Voice Chat for a game session participants.

---

# Project Setup

Create new Unity Project. For this tutorial we'll be using the 2021.3.0f1 LTS version but any newer version should work fine as well.

Install Stream's Video SDK for Unity

TODO: repeat content from install section

After completing this step you should now see "Stream Video & Audio Chat SDK" package in Project->Packages

![Imported SDK package](../assets/tutorials/audio-room/01.png)

---

# Initialize StreamVideoClient

1. Go to Project window
2. Create new folder called Scripts in your Assets folder
3. Inside the Scripts folder, create a new script file and call it AudioRoomsManager.cs
4. Open AudioRoomsManager.cs in your IDE and replace it with the following script:
```csharp
using System;
using StreamVideo.Core;
using StreamVideo.Libs.Auth;
using UnityEngine;

public class AudioRoomsManager : MonoBehaviour
{
    async void Start()
    {
        // Create Client instance
        _client = StreamVideoClient.CreateDefaultClient();

        var credentials = new AuthCredentials(_apiKey, _userId, _userToken);

        try
        {
            // Connect user to Stream server
            await _client.ConnectUserAsync(credentials);
            Debug.Log($"User `{_userId}` is connected to Stream server");
        }
        catch (Exception e)
        {
            // Log potential issues that occured during trying to connect
            Debug.LogException(e);
        }
    }

    [SerializeField]
    private string _apiKey;
    
    [SerializeField]
    private string _userId;
    
    [SerializeField]
    private string _userToken;

    private IStreamVideoClient _client;
}
```

Let's go through this script step by step to understand what we're doing.

This part defines variables for the **api key**, **user id** and the **user token** . These 3 variables are essential to establish a connection for a user.
```csharp
    [SerializeField]
    private string _apiKey;
    
    [SerializeField]
    private string _userId;
    
    [SerializeField]
    private string _userToken;
```

Here we instantiate a default client for the Stream's Video SDK:
```csharp
_client = StreamVideoClient.CreateDefaultClient();
```
Next, we wrap the authorization credentials in a convenient structure:
```csharp
var credentials = new AuthCredentials(_apiKey, _userId, _userToken);
```
And finally, we call the ConnectUserAsync that will attempt to establish a connection:
```csharp
await _client.ConnectUserAsync(credentials);
```
Please note that we're using .NET's modern async/await syntax, this makes writing asynchronous code that wait for server response very easy.

After the `await` completes, we should now be connected to the stream server.

Please also note that we've wrapped the asynchronous `ConnectUserAsync` method in a try/catch block. Unless you're proficient with .NET's async/await syntax and understand how to properly handle exceptions for asynchronous methods, we advise you to always wrap awaited methods in a try/catch block in order to catch any thrown exceptions and therefore be notified about any errors that occured during async operation.

Now go to Scene Hierarchy Window and create an empty game object and call it `AudioRoomsManager`:

![Created AudioRoomsManager empty Game Object](../assets/tutorials/audio-room/02.png)

Next, drag in the newly created `AudioRoomsManager.cs` script onto the AudioRoomsManager game object and save the scene.

You should now have a game object with our `AudioRoomsManager.cs` script attached. Once you select this game object you should see `Api Key`, `User Id`, and the User Token fields exposed in the Inspector Window.

![GameObject with attached AudioRoomsManager.cs script](../assets/tutorials/audio-room/03.png)

---

# Connect a user to Stream server

To actually run this script we need a valid user token. The user token is typically generated by your server side API. When a user logs in to your app you return the user token that gives them access to the call. To make this tutorial easier to follow we'll generate a user token for you:

<TokenSnippet sampleApp='audio-rooms' />

Copy `api key`, `user id`, and the `user token` from the window above and paste them into `AudioRoomsManager` exposed fields:

![Filled Credentials](../assets/tutorials/audio-room/04.png)

After you run the project, you should now see a log confirming that the user is connected to the stream server

---

# Add methods to `Join` and `Leave` a call

In this step we'll add methods to `Join` and `Leave` the call. These will be called from our UI when the user clicks on the `Join` and `Leave` buttons.

First, add this field to the `AudioRoomsManager` class:
```csharp
private IStreamCall _activeCall;
```

So the fields part of the class will look like this:
```csharp
    [SerializeField]
    private string _apiKey;
    
    [SerializeField]
    private string _userId;
    
    [SerializeField]
    private string _userToken;

    private IStreamVideoClient _client;

    // highlight-next-line
    private IStreamCall _activeCall;
```

Next, add the `JoinCallAsync` and the `LeaveCallAsync` methods to the `AudioRoomsManager` class.

```csharp
    public async Task JoinCallAsync(string callId)
    {
        _activeCall = await _client.JoinCallAsync(StreamCallType.Default, callId, create: true, ring: false, notify: false);
    }
    
    public async Task LeaveCallAsync()
    {
        if (_activeCall == null)
        {
            Debug.LogWarning("Leave request ignored. There is no active call to leave.");
            return;
        }

        await _activeCall.LeaveAsync();
    }
```

# Create UI scripts

1. In Scripts folder create new script and call it AudioRoomsUI.cs
2. Open this script in your IDE and paste the following content:
```csharp
using System;
using TMPro;
using UnityEngine;
using UnityEngine.UI;

public class AudioRoomsUI : MonoBehaviour
{
    // Awake is called automatically by Unity Engine
    private void Awake()
    {
        // Add listeners to when user clicks on the buttons
        _joinButton.onClick.AddListener(OnJoinButtonClicked);
        _leaveButton.onClick.AddListener(OnLeaveButtonClicked);
        
        // Remove default option
        _microphoneDropdown.ClearOptions();
        // Populate dropdown with available microphone devices
        _microphoneDropdown.AddOptions(Microphone.devices.ToList());
    }

    private async void OnLeaveButtonClicked()
    {
        try
        {
            await _audioRoomsManager.LeaveCallAsync();
        }
        catch (Exception e)
        {
            Debug.LogException(e);
        }
    }

    private async void OnJoinButtonClicked()
    {
        if (string.IsNullOrEmpty(_callIdInput.text))
        {
            Debug.LogError("Please provide call ID");
            return;
        }

        try
        {
            await _audioRoomsManager.JoinCallAsync(_callIdInput.text);
        }
        catch (Exception e)
        {
            Debug.LogException(e);
        }
    }
    
    [SerializeField]
    private TMP_InputField _callIdInput;

    [SerializeField]
    private Button _joinButton;
    
    [SerializeField]
    private Button _leaveButton;

    [SerializeField]
    private AudioRoomsManager _audioRoomsManager;
    
    // Microphone will use this AudioSource as an audio buffer
    private AudioSource _microphoneAudioSource;

    // Currently active microphone device
    private string _activeMicrophoneDevice;
}
```

Let's break this down.

At the very bottom we've defined fields that will hold references to:
- Join & Leave buttons
- Input that we'll use to provide a call ID to connect
- Dropdown that we'll use to pick the active microphone device
- reference to our AudioRoomsManager
- reference to an `AudioSource` to which active microphone will send audio input
- reference to active microphone device name. In Unity, we use the microphone device name to start & stop streaming audio from the microphone.
```csharp
    [SerializeField]
    private TMP_InputField _callIdInput;

    [SerializeField]
    private Button _joinButton;
    
    [SerializeField]
    private Button _leaveButton;
    
    [SerializeField]
    private TMP_Dropdown _microphoneDropdown;

    [SerializeField]
    private AudioRoomsManager _audioRoomsManager;
    
    // Microphone will use this AudioSource as an audio buffer
    private AudioSource _microphoneAudioSource;

    // Currently active microphone device
    private string _activeMicrophoneDevice;
```

Here, in Unity's Awake special event method, we:
* subscribe `OnJoinButtonClicked` callback method to the join button click event and
* subscribe `OnLeaveButtonClicked` callback to the leave button click event
* Generate dropdown options based on Unity's `Microphone.devices` array
```csharp
    private void Awake()
    {
        // Add listeners to when user clicks on the buttons
        _joinButton.onClick.AddListener(OnJoinButtonClicked);
        _leaveButton.onClick.AddListener(OnLeaveButtonClicked);
        
        // Remove default option
        _microphoneDropdown.ClearOptions();
        // Populate dropdown with available microphone devices
        _microphoneDropdown.AddOptions(Microphone.devices.ToList());
    }
```

The `OnJoinButtonClicked` triggered when user clicks the Join button checks if the call id is set in the input and if it is it then calls the `JoinCallAsync` on our `AudioRoomsManager`:
```csharp
    private async void OnJoinButtonClicked()
    {
        // Validate input
        if (string.IsNullOrEmpty(_callIdInput.text))
        {
            Debug.LogError("Please provide call ID");
            return;
        }

        try
        {
            await _audioRoomsManager.JoinCallAsync(_callIdInput.text);
        }
        catch (Exception e)
        {
            Debug.LogException(e);
        }
    }
```

The `OnLeaveButtonClicked` triggered when user clicks the Leave button calls the `LeaveCallAsync` on our `AudioRoomsManager`:
```csharp
    private async void OnLeaveButtonClicked()
    {
        try
        {
            await _audioRoomsManager.LeaveCallAsync();
        }
        catch (Exception e)
        {
            Debug.LogException(e);
        }
    }
```

# Handle microphone

In order to send audio from our microphone we need to add few more things to our `AudioRoomsUI.cs`.

First, add this method to the `AudioRoomsUI` class:
```csharp
    private void SetActiveMicrophone(int value)
    {
        // Dropdown onValueChanged callback will give us the index of the selected option and we need a device name so we extract it from options
        _activeMicrophoneDevice = _microphoneDropdown.options[value].text;
        
        // If previous microphone device was active -> stop it
        if (_activeMicrophoneDevice != null)
        {
            Microphone.End(_activeMicrophoneDevice);
        }
        
        // Get microphone input 
        _microphoneAudioSource.clip
            = Microphone.Start(_activeMicrophoneDevice, true, 3, AudioSettings.outputSampleRate);
        _microphoneAudioSource.loop = true;
        _microphoneAudioSource.volume = 0; // Set volume to 0 so we don't hear back our microphone
        _microphoneAudioSource.Play();
    }
```
The `SetActiveMicrophone` method will be called whenever a user picks a new microphone device from the dropdown. The `int value` parameter will be populated by the dropdown `onValueChanged` event as we'll soon see.

Let's break down this method:

Because the dropdown `onValueChanged` event will provide us the `index` of the selected option, and we need the actual device name to interact with the microphone, we extract the selected device name with:
```csharp
_activeMicrophoneDevice = _microphoneDropdown.options[value].text;
```

If the microphone device gets changed multiple times we must always stop the previous microphone before activating the new one and we achieve this with the following code:
```csharp
// If previous microphone device was active -> stop it
if (_activeMicrophoneDevice != null)
{
    Microphone.End(_activeMicrophoneDevice);
}
```

Finally, we use Unity's `Microphone.Start` method to start capturing the audio from the microphone device and stream it into `_microphoneAudioSource` AudioSource component that we'll later set as an audio input source for the audio calls.

If your curious about why microphone audio is captured in this way you can refer to [Unity documentation](https://docs.unity3d.com/ScriptReference/Microphone.Start.html) for more information.

Next, add this method to the `AudioRoomsUI` class as well:
```csharp
    private void InitMicrophone()
    {
        // Create AudioSource
        _microphoneAudioSource = gameObject.AddComponent<AudioSource>();

        // Set this AudioSource to be used for Audio Input
        _audioRoomsManager.SetInputAudioSource(_microphoneAudioSource);
        
        // Set first microphone device active. User can change active microphone via dropdown
        SetActiveMicrophone(0);
    }
```

In the `InitMicrophone` method we:
1. Create `AudioSource` component and save its reference in the `_microphoneAudioSource` field.
2. We pass this `AudioSource` to the `_audioRoomsManager.SetInputAudioSource` method so that we can later pass this reference to the Stream's SDK. We'll create this method in the next step.
3. Lastly we call `SetActiveMicrophone(0);` in order to enable first microphone device as an active microphone

As the last step in this section, open the `AudioRoomsManager.cs` class and and the following method:
```csharp
    public void SetInputAudioSource(AudioSource audioSource)
    {
        _inputAudioSource = audioSource;
    }
```

# Create UI scene objects

Go to scene hierarchy window and create the `Canvas` game object. One way to do this is by clicking the `GameObject -> UI -> Canvas` from the top menu.

![Created Canvas GameObject](../assets/tutorials/audio-room/05.png)

Now, create these UI elements as a children of the `Canvas` game object:
- Button
 - name the Game Object as `JoinButton`
 - on the `RectTransform` component set the `Pos X` to `-200` and the `Pos Y` to `25`
 - click on the inner game object, and on the `TextMeshPro - Text(UI)` component, change the text to `Join`
- Second Button
 - name the Game Object as `LeaveButton`
 - on the `RectTransform` component set the `Pos X` to `-200` and the `Pos Y` to `-25`
 - click on the inner game object, and on the `TextMeshPro - Text(UI)` component, change the text to `Leave`
- Input Field 
 - name the GameObject as `CallIdInput`
- Dropdown
 - name the GameObject as `MicrophoneDropdown`
 - on the `RectTransform` component set the `Pos X` to `250` and the `Width` to `300`

One way to do this is to right-click on the `Canvas` object and select those items from the `UI` submenu.

![Created Canvas GameObject](../assets/tutorials/audio-room/06.png)

After completing this step you should see the newly created UI elements when switching over to the `Game` window:

![Created Canvas GameObject](../assets/tutorials/audio-room/07b.png)

Now attach the `AudioRoomsUI.cs` script to the `Canvas` game object and in the Inspector window drag references to the:
* Join Button
* Leave Button
* Call Id Input
* Microphone Dropdown
* AudioRoomsManager

After completing this step you should now have a `Canvas` object with `AudioRoomsUI` component and all references attached:

![Created Canvas GameObject](../assets/tutorials/audio-room/08b.png)

**Save the scene.**

Now, open the `AudioRoomsManager.cs` script again, and add the missing `JoinCallAsync` and the `LeaveCallAsync` methods:
```csharp
    public async Task JoinCallAsync(string callId)
    {
        _activeCall = await _client.JoinCallAsync(StreamCallType.AudioRoom, callId, create: true, ring: false, notify: false);
    }

    public async Task LeaveCallAsync()
    {
        if (_activeCall == null)
        {
            Debug.LogWarning("Leave request ignored. There is no active call to leave.");
            return;
        }

        await _activeCall.LeaveAsync();
    }
```

# Handling participants







# Final scripts

Here are the final scripts for reference:

<details><summary>AudioRoomsUI.cs</summary>
    <p>

```csharp
using System;
using System.Linq;
using TMPro;
using UnityEngine;
using UnityEngine.UI;

public class AudioRoomsUI : MonoBehaviour
{
    // Awake is called automatically by Unity Engine
    private void Awake()
    {
        // Add listeners to when user clicks on the buttons
        _joinButton.onClick.AddListener(OnJoinButtonClicked);
        _leaveButton.onClick.AddListener(OnLeaveButtonClicked);
        
        // Remove default option
        _microphoneDropdown.ClearOptions();
        // Populate dropdown with available microphone devices
        _microphoneDropdown.AddOptions(Microphone.devices.ToList());
        
        // Add listener method to when user changes microphone in the dropdown
        _microphoneDropdown.onValueChanged.AddListener(SetActiveMicrophone);

        InitMicrophone();
    }

    private void InitMicrophone()
    {
        // Create AudioSource
        _microphoneAudioSource = gameObject.AddComponent<AudioSource>();

        // Set this AudioSource to be used for Audio Input
        _audioRoomsManager.SetInputAudioSource(_microphoneAudioSource);
        
        // Set first microphone device active. User can change active microphone via dropdown
        SetActiveMicrophone(0);
    }

    private void SetActiveMicrophone(int value)
    {
        // Dropdown onValueChanged callback will give us the index of the selected option and we need a device name so we extract it from options
        _activeMicrophoneDevice = _microphoneDropdown.options[value].text;
        
        // If previous microphone device was active -> stop it
        if (_activeMicrophoneDevice != null)
        {
            Microphone.End(_activeMicrophoneDevice);
        }
        
        // Get microphone input 
        _microphoneAudioSource.clip
            = Microphone.Start(_activeMicrophoneDevice, true, 3, AudioSettings.outputSampleRate);
        _microphoneAudioSource.loop = true;
        _microphoneAudioSource.volume = 0; // Set volume to 0 so we don't hear back our microphone
        _microphoneAudioSource.Play();
    }

    private async void OnLeaveButtonClicked()
    {
        try
        {
            await _audioRoomsManager.LeaveCallAsync();
        }
        catch (Exception e)
        {
            Debug.LogException(e);
        }
    }

    private async void OnJoinButtonClicked()
    {
        // Validate input
        if (string.IsNullOrEmpty(_callIdInput.text))
        {
            Debug.LogError("Please provide call ID");
            return;
        }

        try
        {
            await _audioRoomsManager.JoinCallAsync(_callIdInput.text);
        }
        catch (Exception e)
        {
            Debug.LogException(e);
        }
    }
    
    [SerializeField]
    private TMP_InputField _callIdInput;

    [SerializeField]
    private Button _joinButton;
    
    [SerializeField]
    private Button _leaveButton;
    
    [SerializeField]
    private TMP_Dropdown _microphoneDropdown;

    [SerializeField]
    private AudioRoomsManager _audioRoomsManager;

    // Microphone will use this AudioSource as an audio buffer
    private AudioSource _microphoneAudioSource;

    // Currently active microphone device
    private string _activeMicrophoneDevice;
}

```

    </p>
</details>




















### Other built-in features

There are a few more exciting features that you can use to build audio rooms:

- ** Requesting Permissions **: Participants can ask the host for permission to speak, share video etc
- ** Query Calls **: You can query calls to easily show upcoming calls, calls that recently finished etc
- ** Call Previews **: Before you join the call you can observe it and show a preview. IE John, Sarah and 3 others are on this call.
- ** Reactions & Custom events **: Reactions and custom events are supported
- ** Recording & Broadcasting **: You can record your calls, or broadcast them to HLS
- ** Chat **: Stream's chat SDKs are fully featured and you can integrate them in the call
- ** Moderation **: Moderation capabilities are built-in to the product
- ** Transcriptions **: Transcriptions aren't available yet, but are coming soon

### Recap

It was fun to see just how quickly you can build an audio-room for your app.
Please do let us know if you ran into any issues.
Our team is also happy to review your UI designs and offer recommendations on how to achieve it with Stream.

Calls run on Stream's global edge network of video servers.
Being closer to your users improves the latency and reliability of calls.
For audio rooms we use Opus RED and Opus DTX for optimal audio quality.

The SDKs enable you to build audio rooms, video calling and livestreaming in days.

We hope you've enjoyed this tutorial, and please do feel free to reach out if you have any suggestions or questions.
