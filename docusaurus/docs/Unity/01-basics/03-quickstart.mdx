---
title: Quickstart
description: For when you're in a hurry and want to quickly get up and running
---

import { TokenSnippet } from '../../../shared/_tokenSnippet.jsx';

This quickstart gives you a quick overview of how Stream's video SDKs work

## Client setup

1. Create the client using `StreamVideoClient.CreateDefaultClient();`
2. Connect a user to Stream server with `await _client.ConnectUserAsync(authCredentials)`

Full example:
```csharp
using System;
using StreamVideo.Core;
using StreamVideo.Libs.Auth;
using UnityEngine;

public class VideoClient : MonoBehaviour
{
    async void Start()
    {
        _client = StreamVideoClient.CreateDefaultClient();

        try
        {
            var authCredentials = new AuthCredentials("api-key", "user-id", "user-token");
            await _client.ConnectUserAsync(authCredentials);
            
            // After the await ConnectUserAsync task completes, the client is connected
        }
        catch (Exception e)
        {
            Debug.LogError(e.Message);
        }
    }

    private IStreamVideoClient _client;
}
```

For testing purposes you can use the following authorization credentials:
<TokenSnippet sampleApp='meeting' displayStyle='credentials'/>

Read more on client authorization and obtaining auth tokens in the [Client & Authentication](./guides/client-auth/) section.

## Creating a call



## Using microphone as an audio input

### Bind microphone device to a `AudioSource` component

This code will get the first microphone device from Unity's `Microphone.devices` list and stream it's input into a `AudioSource` component.

```csharp
// Obtain reference to an AudioSource that will be used a source of audio
var inputAudioSource = GetComponent<AudioSource>();

// Get a valid microphone device name.
// You usually want to populate a dropdown list with Microphone.devices so that the user can pick which device should be used
_activeMicrophoneDeviceName = Microphone.devices.First();

inputAudioSource.clip
    = Microphone.Start(_activeMicrophoneDeviceName, true, 3, AudioSettings.outputSampleRate);
inputAudioSource.loop = true;
inputAudioSource.Play();
```

- For standalone platforms like Windows, macOS, and Linux, you usually want to provide the user with a dropdown menu populated from the `Microphone.devices` so that the user can select the active microphone.
- For mobile platforms like Android or IOS the underlying OS is controlling the devices and the `Microphone.devices`

Please also note that on mobile platforms you need to request appropriate [User Permissions](https://docs.unity3d.com/ScriptReference/Android.Permission.RequestUserPermission.html) in order to make use of the Microphone and the Camera.

### Set `AudioSource` component as an input source for audio.

You can provide any `AudioSource` component as an input for audio. All you need to do is call the `_client.SetAudioInputSource(audioSource)` method as in the following example:
```csharp
// Obtain reference to an AudioSource that will be used a source of audio
var audioSource = GetComponent<AudioSource>();
_client.SetAudioInputSource(audioSource);
```
Now the provided `AudioSource` will be used as an audio input for audio communication in calls.

Please note that the `AudioSrouce` does not necessarily need to be associated with a microphone device. This is indeed the most common use case but the `AudioSource` in fact serves as an audio buffer, so you can implement many other use cases with how the audio input is gathered.

## More information

Please refer to Unity's documentation for more information on how to use Microphone devices:
* [Microphone.devices](https://docs.unity3d.com/ScriptReference/Microphone-devices.html)
* [Microphone.Start](https://docs.unity3d.com/ScriptReference/Microphone.Start.html)
* [Microphone.End](https://docs.unity3d.com/ScriptReference/Microphone.End.html)

## Using camera as a video input

You can use Unity's [WebCamTexture](https://docs.unity3d.com/ScriptReference/WebCamTexture.html) to interact with the camera device.

Once you select the camera device you should create a new instance of `WebCamTexture` and call `Play()` on it.

Now you can set the `WebCamTexture` as a video input with `_client.SetCameraInputSource(activeCamera);` as shown in the following example:
```csharp
// Obtain a camera device
var cameraDevice = WebCamTexture.devices.First();

var width = 1920;
var height = 1080;
var fps = 30;

// Use device name to create a new WebCamTexture instance
var activeCamera = new WebCamTexture(cameraDevice.name, width, height, fps);

// Call Play() in order to start capturing the video
activeCamera.Play();

// Set WebCamTexture in Stream's Client - this WebCamTexture will be the video source in video calls
_client.SetCameraInputSource(activeCamera);
```

- For standalone platforms like Windows, macOS, and Linux, you usually want to provide the user with a dropdown menu populated from the `WebCamTexture.devices` so that the user can select the active camera.
- On mobile platforms like Android or IOS there will usually be two camera devices present in the `WebCamTexture.devices`: The front camera and the back camera. So you may either select the front camera automatically or give user an option to toggle between front and back cameras depending on your use case.

## More information

Please refer to Unity's documentation for more information on how to use Camera devices:
* [WebCamTexture](https://docs.unity3d.com/ScriptReference/WebCamTexture.html)
* [WebCamTexture.devices](https://docs.unity3d.com/ScriptReference/WebCamTexture-devices.html)
* [WebCamTexture.Play](https://docs.unity3d.com/ScriptReference/WebCamTexture.Play.html)
* [WebCamTexture.Stop](https://docs.unity3d.com/ScriptReference/WebCamTexture.Stop.html)